{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bfa7ab7d9c084d39903b10748a50560e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cc4d6a984c74897a0ebc90a866cc799",
              "IPY_MODEL_28147731e9ce48c1beb26da2dfe3577c",
              "IPY_MODEL_1b89edd7f5324ba98fb4a5fe1d1d703e"
            ],
            "layout": "IPY_MODEL_77c6f498bd664666b40466db9983dcec"
          }
        },
        "4cc4d6a984c74897a0ebc90a866cc799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a5f6a928cd54ffaaabbfc6d4bfab7e6",
            "placeholder": "​",
            "style": "IPY_MODEL_0dfb43e23c1c429092e46fb864f9badf",
            "value": "100%"
          }
        },
        "28147731e9ce48c1beb26da2dfe3577c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a0576e897394e2db5b038f5de3b69d7",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_102fcedcd9e5412caada183cd321d612",
            "value": 10000
          }
        },
        "1b89edd7f5324ba98fb4a5fe1d1d703e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77eff2dc88ea4aa3ac72526fa356874d",
            "placeholder": "​",
            "style": "IPY_MODEL_364448439137448c8fba0cdb304d9bb7",
            "value": " 10000/10000 [06:25&lt;00:00, 58.87it/s]"
          }
        },
        "77c6f498bd664666b40466db9983dcec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a5f6a928cd54ffaaabbfc6d4bfab7e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dfb43e23c1c429092e46fb864f9badf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a0576e897394e2db5b038f5de3b69d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "102fcedcd9e5412caada183cd321d612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77eff2dc88ea4aa3ac72526fa356874d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "364448439137448c8fba0cdb304d9bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Data"
      ],
      "metadata": {
        "id": "qQFDxys2w0Td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install torch-sparse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHnVrGWAuxTj",
        "outputId": "193d837b-4f6e-4a0d-b6f9-39e710aafc32"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.16.tar.gz (208 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 208.2/208.2 KB 8.7 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py): started\n",
            "  Building wheel for torch-sparse (setup.py): finished with status 'done'\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.16-cp38-cp38-linux_x86_64.whl size=2679799 sha256=df17b94dbe4a793f77f60256019daa043e0af18de1e6f61d0cc4cb59e1a87424\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/f5/41/86610d3a3ce0bec241d8549ecdd6c7e07fe000e041616cfcd6\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install torch-scatter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjuA0C9obM22",
        "outputId": "5637d145-0aa9-47e3-829f-13ee128bb99d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.0.tar.gz (106 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 106.8/106.8 KB 12.1 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py): started\n",
            "  Building wheel for torch-scatter (setup.py): finished with status 'done'\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.0-cp38-cp38-linux_x86_64.whl size=3372317 sha256=0447db5c000d6125aab1e991ec4ad9b4d7b5aa84182b1c0afda181bad9ab5b6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/7f/4f/cf072bea3b6efe4561de2db3603ebbd8718c134c24caab8281\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import torch; print(torch.__version__)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gq_mniTw1cA",
        "outputId": "cb40be2c-ddae-40b2-b45b-9c1af81a5e2f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import torch; print(torch.version.cuda)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2s7E26rxI-K",
        "outputId": "9363e8cc-2607-45b8-f413-fca67f67aac7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "ljomvur6xhKH",
        "outputId": "69a490bf-59cc-4922-e433-f24a24c830e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.25.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=231b1c82828096c56dad828f850eca52e9ebeb3cfbedd8767d1e90918937462a\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/a3/20/198928106d3169865ae73afcbd3d3d1796cf6b429b55c65378\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: psutil, torch-geometric\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed psutil-5.9.4 torch-geometric-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "SFHzTWtBxlI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection, metrics, preprocessing\n",
        "import copy\n",
        "\n",
        "from torch_geometric.utils import degree \n",
        "\n",
        "import torch \n",
        "from torch import nn, optim, Tensor \n",
        "\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.data import download_url , extract_zip\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.typing import Adj"
      ],
      "metadata": {
        "id": "D981JUOvxu0G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "f01SQO1x53lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the dataset\n",
        "# https://grouplens.org/datasets/movielens\n",
        "# \"small : 100,000 rating and 3,600 tag applications applied to 9,000 movies by 600users. Last updated 9/2018\"\n",
        "\n",
        "url = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "movie_path = './ml-latest-small/movies.csv'\n",
        "rating_path = './ml-latest-small/ratings.csv'\n",
        "user_path = './ml-latest-small/users.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XEvNYwS6vZe",
        "outputId": "9af4b964-0de9-48ae-8571-aa3841223788"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Extracting ./ml-latest-small.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rating_df = pd.read_csv(rating_path)\n",
        "\n",
        "print(rating_df)\n",
        "\n",
        "print(len(rating_df['movieId'].unique()))\n",
        "print(len(rating_df['userId'].unique()))\n",
        "\n",
        "rating_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "P-n8jSVi7w1L",
        "outputId": "fef953bc-93a0-4b5f-cf9b-fd72b35bc159"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        userId  movieId  rating   timestamp\n",
            "0            1        1     4.0   964982703\n",
            "1            1        3     4.0   964981247\n",
            "2            1        6     4.0   964982224\n",
            "3            1       47     5.0   964983815\n",
            "4            1       50     5.0   964982931\n",
            "...        ...      ...     ...         ...\n",
            "100831     610   166534     4.0  1493848402\n",
            "100832     610   168248     5.0  1493850091\n",
            "100833     610   168250     5.0  1494273047\n",
            "100834     610   168252     5.0  1493846352\n",
            "100835     610   170875     3.0  1493846415\n",
            "\n",
            "[100836 rows x 4 columns]\n",
            "9724\n",
            "610\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              userId        movieId         rating     timestamp\n",
              "count  100836.000000  100836.000000  100836.000000  1.008360e+05\n",
              "mean      326.127564   19435.295718       3.501557  1.205946e+09\n",
              "std       182.618491   35530.987199       1.042529  2.162610e+08\n",
              "min         1.000000       1.000000       0.500000  8.281246e+08\n",
              "25%       177.000000    1199.000000       3.000000  1.019124e+09\n",
              "50%       325.000000    2991.000000       3.500000  1.186087e+09\n",
              "75%       477.000000    8122.000000       4.000000  1.435994e+09\n",
              "max       610.000000  193609.000000       5.000000  1.537799e+09"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80d4ba21-1776-45cb-bef4-735d78172832\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100836.000000</td>\n",
              "      <td>100836.000000</td>\n",
              "      <td>100836.000000</td>\n",
              "      <td>1.008360e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>326.127564</td>\n",
              "      <td>19435.295718</td>\n",
              "      <td>3.501557</td>\n",
              "      <td>1.205946e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>182.618491</td>\n",
              "      <td>35530.987199</td>\n",
              "      <td>1.042529</td>\n",
              "      <td>2.162610e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>8.281246e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>177.000000</td>\n",
              "      <td>1199.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.019124e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>325.000000</td>\n",
              "      <td>2991.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>1.186087e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>477.000000</td>\n",
              "      <td>8122.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.435994e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>610.000000</td>\n",
              "      <td>193609.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.537799e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80d4ba21-1776-45cb-bef4-735d78172832')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80d4ba21-1776-45cb-bef4-735d78172832 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80d4ba21-1776-45cb-bef4-735d78172832');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# perform encoding preprocessing to ensure that user_id and item_id are both \n",
        "# in the range of [0, unique_count] so it won't cause out of bound issue when indexing embeddings\n",
        "lbl_user = preprocessing.LabelEncoder()\n",
        "lbl_movie = preprocessing.LabelEncoder()\n",
        "\n",
        "rating_df.userId = lbl_user.fit_transform(rating_df.userId.values)\n",
        "rating_df.movieId = lbl_movie.fit_transform(rating_df.movieId.values)"
      ],
      "metadata": {
        "id": "nrfDy30F8VWe"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rating_df.userId.max())\n",
        "print(rating_df.movieId.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fGaWFSJtqTz",
        "outputId": "8784fcc5-07d3-4afb-f83c-e0fedc7ba59a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609\n",
            "9723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rating_df.rating.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjYR8Ij1ty9w",
        "outputId": "47e9381b-76af-465f-a726-a7eed5fcbc1b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0    26818\n",
              "3.0    20047\n",
              "5.0    13211\n",
              "3.5    13136\n",
              "4.5     8551\n",
              "2.0     7551\n",
              "2.5     5550\n",
              "1.0     2811\n",
              "1.5     1791\n",
              "0.5     1370\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 프레임을 The Edge 로 변한"
      ],
      "metadata": {
        "id": "80lXvtXVusGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load edges between users and movies\n",
        "def load_edge_csv(df, \n",
        "                  src_index_col, \n",
        "                  dst_index_col, \n",
        "                  link_index_col, \n",
        "                  rating_threshold=3):\n",
        "    \"\"\"Loads csv containing edges between users and items\n",
        "\n",
        "    Args:\n",
        "        src_index_col (str): column name of users\n",
        "        dst_index_col (str): column name of items\n",
        "        link_index_col (str): column name of user item interaction\n",
        "        rating_threshold (int, optional): Threshold to determine positivity of edge. Defaults to 4.\n",
        "\n",
        "    Returns:\n",
        "        list of list: edge_index -- 2 by N matrix containing the node ids of N user-item edges\n",
        "        N here is the number of interactions\n",
        "    \"\"\"\n",
        "    \n",
        "    edge_index = None\n",
        "    \n",
        "    # Constructing COO format edge_index from input rating events\n",
        "    \n",
        "    # get user_ids from rating events in the order of occurance\n",
        "    src = [user_id for user_id in  df['userId']]    \n",
        "    # get movie_id from rating events in the order of occurance\n",
        "    dst = [(movie_id) for movie_id in df['movieId']]\n",
        "\n",
        "    # apply rating threshold\n",
        "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold\n",
        "\n",
        "    edge_index = [[], []]\n",
        "    for i in range(edge_attr.shape[0]):\n",
        "        if edge_attr[i]:\n",
        "            edge_index[0].append(src[i])\n",
        "            edge_index[1].append(dst[i])\n",
        "    return edge_index"
      ],
      "metadata": {
        "id": "CjJ66-iGu-fP"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index = load_edge_csv(\n",
        "    rating_df,\n",
        "    src_index_col='userId',\n",
        "    dst_index_col='movieId',\n",
        "    link_index_col='rating',\n",
        "    rating_threshold=3.5, \n",
        ")\n",
        "\n",
        "print(f\"{len(edge_index)} x {len(edge_index[0])}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHIPVz6C4d9W",
        "outputId": "9473c807-2035-488b-e38f-2df9bb72d38e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 x 48580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to tensor\n",
        "# We use LongTensor here because the .propagate() method in the model needs either LongTensor or SparseTensor\n",
        "edge_index = torch.LongTensor(edge_index) \n",
        "print(edge_index)\n",
        "print(edge_index.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-SF3WHu4fOz",
        "outputId": "b81c0a15-ee2c-43db-eb7c-6e3d8a6d41b7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
            "        [   0,    2,    5,  ..., 9443, 9444, 9445]])\n",
            "torch.Size([2, 48580])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: this is the total num_users and num_movies before we apply the rating_threshold\n",
        "num_users = len(rating_df['userId'].unique())\n",
        "num_movies = len(rating_df['movieId'].unique())"
      ],
      "metadata": {
        "id": "kJUY5cwg4hnl"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_interactions = edge_index.shape[1]\n",
        "\n",
        "# split the edges of the graph using a 80/10/10 train/validation/test split\n",
        "all_indices = [i for i in range(num_interactions)]\n",
        "\n",
        "train_indices, test_indices = train_test_split(all_indices, \n",
        "                                               test_size=0.2, \n",
        "                                               random_state=1)\n",
        "\n",
        "val_indices, test_indices = train_test_split(test_indices, \n",
        "                                             test_size=0.5, \n",
        "                                             random_state=1)\n",
        "\n",
        "train_edge_index = edge_index[:, train_indices]\n",
        "val_edge_index = edge_index[:, val_indices]\n",
        "test_edge_index = edge_index[:, test_indices]"
      ],
      "metadata": {
        "id": "FElnsxDc5eeW"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"num_users {num_users}, num_movies {num_movies}, num_interactions {num_interactions}\")\n",
        "print(f\"train_edge_index {train_edge_index}\")\n",
        "print((num_users + num_movies))\n",
        "print(torch.unique(train_edge_index[0]).size())\n",
        "print(torch.unique(train_edge_index[1]).size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqZ20b8256nN",
        "outputId": "81f08cdf-bd23-46fb-a12f-aa1f898ecbf4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_users 610, num_movies 9724, num_interactions 48580\n",
            "train_edge_index tensor([[ 605,  110,  442,  ...,   65,  161,  427],\n",
            "        [1110, 9619, 1283,  ..., 4640,  443,  827]])\n",
            "10334\n",
            "torch.Size([609])\n",
            "torch.Size([5676])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_r_mat_edge_index_to_adj_mat_edge_index(input_edge_index):\n",
        "    R = torch.zeros((num_users, num_movies))\n",
        "    for i in range(len(input_edge_index[0])):\n",
        "        row_idx = input_edge_index[0][i]\n",
        "        col_idx = input_edge_index[1][i]\n",
        "        R[row_idx][col_idx] = 1\n",
        "\n",
        "    R_transpose = torch.transpose(R, 0, 1)\n",
        "    adj_mat = torch.zeros((num_users + num_movies , num_users + num_movies))\n",
        "    adj_mat[: num_users, num_users :] = R.clone()\n",
        "    adj_mat[num_users :, : num_users] = R_transpose.clone()\n",
        "    adj_mat_coo = adj_mat.to_sparse_coo()\n",
        "    adj_mat_coo = adj_mat_coo.indices()\n",
        "    return adj_mat_coo"
      ],
      "metadata": {
        "id": "yh44kPQ-5nc4"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index):\n",
        "    sparse_input_edge_index = SparseTensor(row=input_edge_index[0], \n",
        "                                           col=input_edge_index[1], \n",
        "                                           sparse_sizes=((num_users + num_movies), num_users + num_movies))\n",
        "    adj_mat = sparse_input_edge_index.to_dense()\n",
        "    interact_mat = adj_mat[: num_users, num_users :]\n",
        "    r_mat_edge_index = interact_mat.to_sparse_coo().indices()\n",
        "    return r_mat_edge_index"
      ],
      "metadata": {
        "id": "BwlXAdgP5pCd"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert from r_mat (interaction matrix) edge index to adjescency matrix's edge index \n",
        "# so we can feed it to model\n",
        "train_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(train_edge_index)\n",
        "val_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(val_edge_index)\n",
        "test_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(test_edge_index)"
      ],
      "metadata": {
        "id": "2tA8sMek5qS8"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_edge_index)\n",
        "print(train_edge_index.size())\n",
        "print(val_edge_index)\n",
        "print(val_edge_index.size())\n",
        "print(test_edge_index)\n",
        "print(test_edge_index.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60jlJX915ry7",
        "outputId": "94070d59-1c66-4c94-f5e3-f3d0cd998458"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     0,     0,  ..., 10326, 10327, 10333],\n",
            "        [  610,   612,   653,  ...,   183,   183,   330]])\n",
            "torch.Size([2, 77728])\n",
            "tensor([[    0,     0,     0,  ..., 10226, 10236, 10240],\n",
            "        [  615,   794,  2010,  ...,   317,   204,   413]])\n",
            "torch.Size([2, 9716])\n",
            "tensor([[    0,     0,     0,  ..., 10301, 10302, 10329],\n",
            "        [  811,  1086,  1095,  ...,   585,   585,   183]])\n",
            "torch.Size([2, 9716])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function for training and compute BPR loss\n",
        "# since this is a self-supervised learning, we are relying on the graph structure itself and \n",
        "# we don't have label other than the graph structure so we need to the folloing function\n",
        "# which random samples a mini-batch of positive and negative samples\n",
        "def sample_mini_batch(batch_size, edge_index):\n",
        "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): minibatch size\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        tuple: user indices, positive item indices, negative item indices\n",
        "    \"\"\"\n",
        "    # structured_negative_sampling is a pyG library\n",
        "    # Samples a negative edge :obj:`(i,k)` for every positive edge\n",
        "    # :obj:`(i,j)` in the graph given by :attr:`edge_index`, and returns it as a\n",
        "    # tuple of the form :obj:`(i,j,k)`.\n",
        "    #\n",
        "    #         >>> edge_index = torch.as_tensor([[0, 0, 1, 2],\n",
        "    #         ...                               [0, 1, 2, 3]])\n",
        "    #         >>> structured_negative_sampling(edge_index)\n",
        "    #         (tensor([0, 0, 1, 2]), tensor([0, 1, 2, 3]), tensor([2, 3, 0, 2]))\n",
        "    edges = structured_negative_sampling(edge_index)\n",
        "    \n",
        "    # 3 x edge_index_len\n",
        "    edges = torch.stack(edges, dim=0)\n",
        "    \n",
        "    # here is whhen we actually perform the batch sampe\n",
        "    # Return a k sized list of population elements chosen with replacement.\n",
        "    indices = random.choices([i for i in range(edges[0].shape[0])], k=batch_size)\n",
        "    \n",
        "    batch = edges[:, indices]\n",
        "    \n",
        "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
        "    return user_indices, pos_item_indices, neg_item_indices"
      ],
      "metadata": {
        "id": "Vl-vYv026y7g"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing LightGCN\n",
        "\n",
        "\n",
        "## Light Graph Convolution\n",
        "Between each layer, LightGCN uses the following propagation rule for user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "e_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}} e_i^{(k)} \\quad e_i^{(k+1)} = \\sum_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}} e_u^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
        "\n",
        "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
        "\n",
        "$e_u^{(k)}$ : k-th layer user embedding\n",
        "\n",
        "$e_i^{(k)}$ : k-th layer item embedding\n",
        "\n",
        "\n",
        "\n",
        "## Layer Combination and Model Prediction\n",
        "The only trainable parameters of LightGCN are the 0-th layer embeddings $e_u^{(0)}$ and $e_i^{(0)}$ for each user and item. We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "e_u = \\sum_{k = 0}^K \\alpha_k e_u^{(k)} \\quad e_i = \\sum_{k = 0}^K \\alpha_k e_i^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$\\alpha_k$ : hyperparameter which weights the contribution of the k-th layer embedding to the final embedding\n",
        "\n",
        "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y}_{ui} = e_u^Te_i\n",
        "\\end{equation}\n",
        "\n",
        "## Matrix Form\n",
        "In our implementation, we utilize the matrix form of LightGCN. We perform multi-scale diffusion to obtain the final embedding, which sums embeddings diffused across multi-hop scales. \n",
        "\n",
        "\\begin{equation}\n",
        "E^{(K)} = \\alpha_0 E^{(0)} + \\alpha_1 \\tilde{A}^1 E^{(0)} + \\alpha_2 \\tilde{A}^2 E^{(0)} + \\cdot \\cdot \\cdot + \\alpha_K \\tilde{A}^K \\tilde{A} E^{(0)}\n",
        "\\end{equation}\n",
        "\n",
        "$E^{(0)} \\in \\mathcal{R}^{(M + N)} \\times T$ : stacked initial item and user embeddings where $M$, $N$, and $T$ denote the number of users, number of items, and the dimension of each embedding respectively\n",
        "\n",
        "$\\tilde{A} = D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$ : symmetrically normalized adjacency matrix\n"
      ],
      "metadata": {
        "id": "rKK5SrJIvVJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defines LightGCN model \n",
        "class LightGCN(MessagePassing):\n",
        "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_users, \n",
        "                 num_items, \n",
        "                 embedding_dim=64, # define the embding vector length for each node\n",
        "                 K=3, \n",
        "                 add_self_loops=False):\n",
        "        \"\"\"Initializes LightGCN Model\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Number of users\n",
        "            num_items (int): Number of items\n",
        "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
        "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
        "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.K = K\n",
        "        self.add_self_loops = add_self_loops\n",
        "\n",
        "        # define user and item embedding for direct look up. \n",
        "        # embedding dimension: num_user/num_item x embedding_dim\n",
        "        \n",
        "        self.users_emb = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
        "        \n",
        "        self.items_emb = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
        "\n",
        "        # \"Fills the input Tensor with values drawn from the normal distribution\"\n",
        "        # according to LightGCN paper, this gives better performance\n",
        "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "\n",
        "    def forward(self, edge_index: Tensor):\n",
        "        \"\"\"Forward propagation of LightGCN Model.\n",
        "\n",
        "        Args:\n",
        "            edge_index (SparseTensor): adjacency matrix\n",
        "\n",
        "        Returns:\n",
        "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "            compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
        "            \\tilde_A = D^(-1/2) * A * D^(-1/2)    according to LightGCN paper\n",
        "        \n",
        "            this is essentially a metrix operation way to get 1/ (sqrt(n_neighbors_i) * sqrt(n_neighbors_j))\n",
        "\n",
        "        \n",
        "            if your original edge_index look like\n",
        "            tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
        "                    [   0,    2,    5,  ..., 9444, 9445, 9485]])\n",
        "                    \n",
        "                    torch.Size([2, 99466])\n",
        "                    \n",
        "            then this will output: \n",
        "                (\n",
        "                 tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
        "                         [   0,    2,    5,  ..., 9444, 9445, 9485]]), \n",
        "                 tensor([0.0047, 0.0096, 0.0068,  ..., 0.0592, 0.0459, 0.1325])\n",
        "                 )\n",
        "                 \n",
        "              where edge_index_norm[0] is just the original edge_index\n",
        "              \n",
        "              and edge_index_norm[1] is the symmetrically normalization term. \n",
        "              \n",
        "            under the hood it's basically doing\n",
        "                def compute_gcn_norm(edge_index, emb):\n",
        "                    emb = emb.weight\n",
        "                    from_, to_ = edge_index\n",
        "                    deg = degree(to_, emb.size(0), dtype=emb.dtype)\n",
        "                    deg_inv_sqrt = deg.pow(-0.5)\n",
        "                    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "                    norm = deg_inv_sqrt[from_] * deg_inv_sqrt[to_]\n",
        "\n",
        "                    return norm\n",
        "                 \n",
        "                \n",
        "        \"\"\"\n",
        "        edge_index_norm = gcn_norm(edge_index=edge_index, \n",
        "                                   add_self_loops=self.add_self_loops)\n",
        "\n",
        "        # concat the user_emb and item_emb as the layer0 embing matrix\n",
        "        # size will be (n_users + n_items) x emb_vector_len.   e.g: 10334 x 64\n",
        "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
        "\n",
        "        embs = [emb_0] # save the layer0 emb to the embs list\n",
        "        \n",
        "        # emb_k is the emb that we are actually going to push it through the graph layers\n",
        "        # as described in lightGCN paper formula 7\n",
        "        emb_k = emb_0 \n",
        "\n",
        "        # push the embedding of all users and items through the Graph Model K times.\n",
        "        # K here is the number of layers\n",
        "        for i in range(self.K):\n",
        "            emb_k = self.propagate(edge_index=edge_index_norm[0], x=emb_k, norm=edge_index_norm[1])\n",
        "            embs.append(emb_k)\n",
        "            \n",
        "            \n",
        "        # this is doing the formula8 in LightGCN paper  \n",
        "            \n",
        "        # the stacked embs is a list of embedding matrix at each layer\n",
        "        #    it's of shape n_nodes x (n_layers + 1) x emb_vector_len. \n",
        "        #        e.g: torch.Size([10334, 4, 64])\n",
        "        embs = torch.stack(embs, dim=1)\n",
        "        \n",
        "        # From LightGCn paper: \"In our experiments, we find that setting α_k uniformly as 1/(K + 1)\n",
        "        #    leads to good performance in general.\"\n",
        "        emb_final = torch.mean(embs, dim=1) # E^K\n",
        "\n",
        "\n",
        "        # splits into e_u^K and e_i^K\n",
        "        users_emb_final, items_emb_final = torch.split(emb_final, [self.num_users, self.num_items]) \n",
        "\n",
        "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
        "        # here using .weight to get the tensor weights from n.Embedding\n",
        "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        # x_j is of shape:  edge_index_len x emb_vector_len\n",
        "        #    e.g: torch.Size([77728, 64]\n",
        "        #\n",
        "        # x_j is basically the embedding of all the neighbors based on the src_list in coo edge index\n",
        "        # \n",
        "        # elementwise multiply by the symmetrically norm. So it's essentiall what formula 7 in LightGCN\n",
        "        # paper does but here we are using edge_index rather than Adj Matrix\n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "layers = 3    \n",
        "model = LightGCN(num_users=num_users, \n",
        "                 num_items=num_movies, \n",
        "                 K=layers)"
      ],
      "metadata": {
        "id": "UutwI9TSvewX"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function\n",
        "\n",
        "\n",
        "\n",
        "We utilize a Bayesian Personalized Ranking (BPR) loss, a pairwise objective which encourages the predictions of positive samples to be higher than negative samples for each user.\n",
        "\n",
        "\\begin{equation}\n",
        "L_{BPR} = -\\sum_{u = 1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln{\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})} + \\lambda ||E^{(0)}||^2 \n",
        "\\end{equation}\n",
        "\n",
        "$\\hat{y}_{u}$: predicted score of a positive sample\n",
        "\n",
        "$\\hat{y}_{uj}$: predicted score of a negative sample\n",
        "\n",
        "$\\lambda$: hyperparameter which controls the L2 regularization strength"
      ],
      "metadata": {
        "id": "nr7QHLhL3gv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bpr_loss(users_emb_final, \n",
        "             users_emb_0, \n",
        "             pos_items_emb_final, \n",
        "             pos_items_emb_0, \n",
        "             neg_items_emb_final, \n",
        "             neg_items_emb_0, \n",
        "             lambda_val):\n",
        "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
        "\n",
        "    Args:\n",
        "        users_emb_final (torch.Tensor): e_u_k\n",
        "        users_emb_0 (torch.Tensor): e_u_0\n",
        "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
        "        pos_items_emb_0 (torch.Tensor): positive e_i_0\n",
        "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
        "        neg_items_emb_0 (torch.Tensor): negative e_i_0\n",
        "        lambda_val (float): lambda value for regularization loss term\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: scalar bpr loss value\n",
        "    \"\"\"\n",
        "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
        "                             pos_items_emb_0.norm(2).pow(2) +\n",
        "                             neg_items_emb_0.norm(2).pow(2)) # L2 loss\n",
        "\n",
        "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
        "    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n",
        "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
        "    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n",
        "\n",
        "\n",
        "    bpr_loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores))\n",
        "    \n",
        "    loss = bpr_loss + reg_loss\n",
        "    \n",
        "    return loss"
      ],
      "metadata": {
        "id": "VFh19ikU6_Yw"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "We evalaluate our model using the following metrics\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Recall} = \\frac{TP}{TP + FP}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Precision} = \\frac{TP}{TP + FN}\n",
        "\\end{equation}\n",
        "\n",
        "Recall@k and Precision@k is just applying only the topK recommended items and then for the overall\n",
        "Recall@k and Precision@k, it's just averaged by the number of users\n",
        "\n",
        "**Dicounted Cumulative Gain (DCG)** at rank position p is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{DCG}_\\text{p} = \\sum_{i = 1}^p \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
        "\\end{equation}\n",
        "\n",
        "p: a particular rank position\n",
        "\n",
        "$rel_i \\in \\{0, 1\\}$ : graded relevance of the result at position $i$\n",
        "\n",
        "**Idealised Dicounted Cumulative Gain (IDCG)**, namely the maximum possible DCG, at rank position $p$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{IDCG}_\\text{p} = \\sum_{i = 1}^{|REL_p|} \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
        "\\end{equation}\n",
        "\n",
        "$|REL_p|$ : list of items ordered by their relevance up to position p\n",
        "\n",
        "**Normalized Dicounted Cumulative Gain (NDCG)** at rank position $p$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{nDCG}_\\text{p} = \\frac{\\text{DCG}_p}{\\text{nDCG}_p}\n",
        "\\end{equation}\n",
        "\n",
        "Specifically, we use the metrics recall@K, precision@K, and NDCG@K. @K indicates that these metrics are computed on the top K recommendations."
      ],
      "metadata": {
        "id": "jS3c7WaS7Dts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_positive_items(edge_index):\n",
        "    \"\"\"\n",
        "    Generates dictionary of positive items for each user\n",
        "\n",
        "    Args:\n",
        "        edge_index (torch.Tensor): 2 by N list of edges \n",
        "\n",
        "    Returns:\n",
        "        dict: user -> list of positive items for each \n",
        "    \"\"\"\n",
        "    \n",
        "    # key: user_id, val: item_id list\n",
        "    user_pos_items = {}\n",
        "    \n",
        "    for i in range(edge_index.shape[1]):\n",
        "        user = edge_index[0][i].item()\n",
        "        item = edge_index[1][i].item()\n",
        "        \n",
        "        if user not in user_pos_items:\n",
        "            user_pos_items[user] = []\n",
        "        \n",
        "        user_pos_items[user].append(item)\n",
        "        \n",
        "    return user_pos_items"
      ],
      "metadata": {
        "id": "B-YsCWsZ7GXa"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computes recall@K and precision@K\n",
        "def RecallPrecision_ATk(groundTruth, r, k):\n",
        "    \"\"\"Computers recall @ k and precision @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list[list[long]]): list of lists of item_ids. Cntaining highly rated items of each user. \n",
        "                            In other words, this is the list of true_relevant_items for each user\n",
        "                            \n",
        "        r (list[list[boolean]]): list of lists indicating whether each top k item recommended to each user\n",
        "                            is a top k ground truth (true relevant) item or not\n",
        "                            \n",
        "        k (int): determines the top k items to compute precision and recall on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k\n",
        "    \"\"\"\n",
        "    \n",
        "    # number of correctly predicted items per user\n",
        "    # -1 here means I want to sum at the inner most dimension\n",
        "    num_correct_pred = torch.sum(r, dim=-1)  \n",
        "    \n",
        "    # number of items liked by each user in the test set\n",
        "    user_num_liked = torch.Tensor([len(groundTruth[i]) for i in range(len(groundTruth))])\n",
        "    \n",
        "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
        "    precision = torch.mean(num_correct_pred) / k\n",
        "    return recall.item(), precision.item()"
      ],
      "metadata": {
        "id": "pIoJ-3na7Il1"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computes NDCG@K\n",
        "def NDCGatK_r(groundTruth, r, k):\n",
        "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (int): determines the top k items to compute ndcg on\n",
        "\n",
        "    Returns:\n",
        "        float: ndcg @ k\n",
        "    \"\"\"\n",
        "    assert len(r) == len(groundTruth)\n",
        "\n",
        "    test_matrix = torch.zeros((len(r), k))\n",
        "\n",
        "    for i, items in enumerate(groundTruth):\n",
        "        length = min(len(items), k)\n",
        "        test_matrix[i, :length] = 1\n",
        "    max_r = test_matrix\n",
        "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
        "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
        "    dcg = torch.sum(dcg, axis=1)\n",
        "    idcg[idcg == 0.] = 1.\n",
        "    ndcg = dcg / idcg\n",
        "    ndcg[torch.isnan(ndcg)] = 0.\n",
        "    return torch.mean(ndcg).item()"
      ],
      "metadata": {
        "id": "S04ou-YU7J-0"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wrapper function to get evaluation metrics\n",
        "def get_metrics(model, \n",
        "                input_edge_index, # adj_mat based edge index\n",
        "                input_exclude_edge_indices, # adj_mat based exclude edge index\n",
        "                k):\n",
        "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        \n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        \n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        \n",
        "        k (int): determines the top k items to compute metrics on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    # get the embedding tensor at layer 0 after training\n",
        "    user_embedding = model.users_emb.weight\n",
        "    item_embedding = model.items_emb.weight\n",
        "    \n",
        "\n",
        "    # convert adj_mat based edge index to r_mat based edge index so we have have \n",
        "    # the first list being user_ids and second list being item_ids for the edge index \n",
        "    edge_index = convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index)\n",
        "\n",
        "    # This is to exclude the edges we have seen before in our predicted interaction matrix (r_mat_rating)\n",
        "    # E.g: for validation set, we want want to exclude all the edges in training set\n",
        "    exclude_edge_indices = [convert_adj_mat_edge_index_to_r_mat_edge_index(exclude_edge_index) \\\n",
        "                                      for exclude_edge_index in input_exclude_edge_indices]\n",
        "\n",
        "     \n",
        "\n",
        "    # Generate predicted interaction matrix (r_mat_rating)    \n",
        "    # (num_users x 64) dot_product (num_item x 64).T \n",
        "    r_mat_rating = torch.matmul(user_embedding, item_embedding.T)\n",
        "    \n",
        "    # shape: num_users x num_item\n",
        "    rating = r_mat_rating\n",
        "   \n",
        "    for exclude_edge_index in exclude_edge_indices:\n",
        "        # gets all the positive items for each user from the edge index\n",
        "        # it's a dict: user -> positive item list\n",
        "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
        "        \n",
        "        # get coordinates of all edges to exclude\n",
        "        exclude_users = []\n",
        "        exclude_items = []\n",
        "        for user, items in user_pos_items.items():\n",
        "            # [user] * len(item) can give us [user1, user1, user1...] with len of len(item)\n",
        "            # this makes easier to do the masking below\n",
        "            exclude_users.extend([user] * len(items))\n",
        "            exclude_items.extend(items)\n",
        "   \n",
        "        # set the excluded entry in the rat_mat_rating matrix to a very small number\n",
        "        rating[exclude_users, exclude_items] = -(1 << 10) \n",
        "\n",
        "    # get the top k recommended items for each user\n",
        "    _, top_K_items = torch.topk(rating, k=k)\n",
        "\n",
        "    # get all unique users in evaluated split\n",
        "    users = edge_index[0].unique()\n",
        "\n",
        "    # dict of user -> pos_item list\n",
        "    test_user_pos_items = get_user_positive_items(edge_index)\n",
        "\n",
        "    # convert test user pos items dictionary into a list of lists\n",
        "    test_user_pos_items_list = [test_user_pos_items[user.item()] for user in users]\n",
        "\n",
        "\n",
        "    # r here is \"pred_relevant_items ∩ actually_relevant_items\" list for each user\n",
        "    r = []\n",
        "    for user in users:\n",
        "        user_true_relevant_item = test_user_pos_items[user.item()]\n",
        "        # list of Booleans to store whether or not a given item in the top_K_items for a given user \n",
        "        # is also present in user_true_relevant_item.\n",
        "        # this is later on used to compute n_rel_and_rec_k\n",
        "        label = list(map(lambda x: x in user_true_relevant_item, top_K_items[user]))\n",
        "        r.append(label)\n",
        "        \n",
        "    r = torch.Tensor(np.array(r).astype('float'))\n",
        "\n",
        "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
        "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
        "\n",
        "    return recall, precision, ndcg"
      ],
      "metadata": {
        "id": "0f5eHK0o7LGD"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wrapper function to evaluate model\n",
        "def evaluation(model, \n",
        "               edge_index, # adj_mat based edge index\n",
        "               exclude_edge_indices,  # adj_mat based exclude edge index\n",
        "               k, \n",
        "               lambda_val\n",
        "              ):\n",
        "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        k (int): determines the top k items to compute metrics on\n",
        "        lambda_val (float): determines lambda for bpr loss\n",
        "\n",
        "    Returns:\n",
        "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    # get embeddings\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(edge_index)\n",
        "    \n",
        "    r_mat_edge_index = convert_adj_mat_edge_index_to_r_mat_edge_index(edge_index)\n",
        "    \n",
        "    edges = structured_negative_sampling(r_mat_edge_index, contains_neg_self_loops=False)\n",
        "    \n",
        "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
        "    \n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    \n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[pos_item_indices], items_emb_0[pos_item_indices]\n",
        "    \n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[neg_item_indices], items_emb_0[neg_item_indices]\n",
        "\n",
        "    loss = bpr_loss(users_emb_final, \n",
        "                    users_emb_0, \n",
        "                    pos_items_emb_final, \n",
        "                    pos_items_emb_0,\n",
        "                    neg_items_emb_final, \n",
        "                    neg_items_emb_0, \n",
        "                    lambda_val).item()\n",
        "\n",
        "\n",
        "    recall, precision, ndcg = get_metrics(model, \n",
        "                                          edge_index, \n",
        "                                          exclude_edge_indices, \n",
        "                                          k)\n",
        "\n",
        "    return loss, recall, precision, ndcg"
      ],
      "metadata": {
        "id": "ZAEaigGt7MHd"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "\n",
        "Your test set performance should be in line with the following (*K=20*):\n",
        "\n",
        "*Recall@K: 0.13, Precision@K: 0.045, NDCG@K: 0.10*"
      ],
      "metadata": {
        "id": "vbM1bun97NtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define contants\n",
        "ITERATIONS = 10000\n",
        "EPOCHS = 10\n",
        "# ITERATIONS = 500\n",
        "BATCH_SIZE = 1024\n",
        "LR = 1e-3\n",
        "ITERS_PER_EVAL = 200\n",
        "ITERS_PER_LR_DECAY = 200\n",
        "K = 20\n",
        "LAMBDA = 1e-6\n",
        "# LAMBDA = 1/2"
      ],
      "metadata": {
        "id": "zyLxHPpG7QdE"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device {device}.\")\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "edge_index = edge_index.to(device)\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "val_edge_index = val_edge_index.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elRJqWAh7R-o",
        "outputId": "dd8425f3-63af-4345-8636-c3375281e365"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cuda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embs_for_bpr(model, input_edge_index):\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(input_edge_index)\n",
        "    \n",
        "\n",
        "    edge_index_to_use = convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index)\n",
        "    \n",
        "    # mini batching for eval and calculate loss \n",
        "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(BATCH_SIZE, edge_index_to_use)\n",
        "    \n",
        "    # This is to push tensor to device so if we are using GPU\n",
        "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
        "    \n",
        " \n",
        "    # we need layer0 embeddings and the final embeddings (computed from 0...K layer) for BPR loss computing\n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[pos_item_indices], items_emb_0[pos_item_indices]\n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[neg_item_indices], items_emb_0[neg_item_indices]\n",
        "   \n",
        "    return users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0"
      ],
      "metadata": {
        "id": "1Xw_gnOx7TC4"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_recall_at_ks = []\n",
        "\n",
        "for iter in tqdm(range(ITERATIONS)):\n",
        "    # forward propagation  \n",
        "    users_emb_final, users_emb_0,  pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0 \\\n",
        "                = get_embs_for_bpr(model, train_edge_index)\n",
        "    \n",
        "    # loss computation\n",
        "    train_loss = bpr_loss(users_emb_final, \n",
        "                          users_emb_0, \n",
        "                          pos_items_emb_final,\n",
        "                          pos_items_emb_0, \n",
        "                          neg_items_emb_final, \n",
        "                          neg_items_emb_0, \n",
        "                          LAMBDA)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # validation set\n",
        "    if iter % ITERS_PER_EVAL == 0:\n",
        "        model.eval()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            val_loss, recall, precision, ndcg = evaluation(model, \n",
        "                                                           val_edge_index, \n",
        "                                                           [train_edge_index], \n",
        "                                                           K, \n",
        "                                                           LAMBDA\n",
        "                                                          )\n",
        "\n",
        "            print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
        "\n",
        "            train_losses.append(train_loss.item())\n",
        "            val_losses.append(val_loss)\n",
        "            val_recall_at_ks.append(round(recall, 5))\n",
        "        model.train()\n",
        "\n",
        "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
        "        scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945,
          "referenced_widgets": [
            "bfa7ab7d9c084d39903b10748a50560e",
            "4cc4d6a984c74897a0ebc90a866cc799",
            "28147731e9ce48c1beb26da2dfe3577c",
            "1b89edd7f5324ba98fb4a5fe1d1d703e",
            "77c6f498bd664666b40466db9983dcec",
            "4a5f6a928cd54ffaaabbfc6d4bfab7e6",
            "0dfb43e23c1c429092e46fb864f9badf",
            "5a0576e897394e2db5b038f5de3b69d7",
            "102fcedcd9e5412caada183cd321d612",
            "77eff2dc88ea4aa3ac72526fa356874d",
            "364448439137448c8fba0cdb304d9bb7"
          ]
        },
        "id": "KU1_vCJ87U51",
        "outputId": "fad0f1d5-1643-4b2b-9471-5f46663e4653"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfa7ab7d9c084d39903b10748a50560e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Iteration 0/10000] train_loss: -0.69301, val_loss: -0.69945, val_recall@20: 0.00212, val_precision@20: 0.00136, val_ndcg@20: 0.0024\n",
            "[Iteration 200/10000] train_loss: -6.81185, val_loss: -5.1868, val_recall@20: 0.05453, val_precision@20: 0.02215, val_ndcg@20: 0.03882\n",
            "[Iteration 400/10000] train_loss: -30.08703, val_loss: -21.25264, val_recall@20: 0.07313, val_precision@20: 0.02929, val_ndcg@20: 0.04888\n",
            "[Iteration 600/10000] train_loss: -61.19833, val_loss: -45.36327, val_recall@20: 0.08996, val_precision@20: 0.03472, val_ndcg@20: 0.06008\n",
            "[Iteration 800/10000] train_loss: -105.24258, val_loss: -74.40412, val_recall@20: 0.10512, val_precision@20: 0.03752, val_ndcg@20: 0.07138\n",
            "[Iteration 1000/10000] train_loss: -157.20256, val_loss: -108.49146, val_recall@20: 0.10687, val_precision@20: 0.03843, val_ndcg@20: 0.07342\n",
            "[Iteration 1200/10000] train_loss: -195.90181, val_loss: -144.89177, val_recall@20: 0.11812, val_precision@20: 0.04051, val_ndcg@20: 0.08044\n",
            "[Iteration 1400/10000] train_loss: -254.33859, val_loss: -184.70879, val_recall@20: 0.11312, val_precision@20: 0.04024, val_ndcg@20: 0.08111\n",
            "[Iteration 1600/10000] train_loss: -313.64084, val_loss: -224.10452, val_recall@20: 0.12113, val_precision@20: 0.04277, val_ndcg@20: 0.08689\n",
            "[Iteration 1800/10000] train_loss: -370.25485, val_loss: -266.02988, val_recall@20: 0.1248, val_precision@20: 0.04367, val_ndcg@20: 0.09185\n",
            "[Iteration 2000/10000] train_loss: -433.46103, val_loss: -304.35333, val_recall@20: 0.12404, val_precision@20: 0.04241, val_ndcg@20: 0.08888\n",
            "[Iteration 2200/10000] train_loss: -483.4039, val_loss: -349.38809, val_recall@20: 0.12545, val_precision@20: 0.04349, val_ndcg@20: 0.09224\n",
            "[Iteration 2400/10000] train_loss: -536.74304, val_loss: -386.75671, val_recall@20: 0.12719, val_precision@20: 0.04286, val_ndcg@20: 0.09256\n",
            "[Iteration 2600/10000] train_loss: -576.44971, val_loss: -429.96198, val_recall@20: 0.13143, val_precision@20: 0.04385, val_ndcg@20: 0.0947\n",
            "[Iteration 2800/10000] train_loss: -673.25354, val_loss: -464.87009, val_recall@20: 0.13082, val_precision@20: 0.04448, val_ndcg@20: 0.09519\n",
            "[Iteration 3000/10000] train_loss: -683.38269, val_loss: -503.74069, val_recall@20: 0.13006, val_precision@20: 0.04412, val_ndcg@20: 0.09599\n",
            "[Iteration 3200/10000] train_loss: -690.9693, val_loss: -544.08661, val_recall@20: 0.12868, val_precision@20: 0.04403, val_ndcg@20: 0.0957\n",
            "[Iteration 3400/10000] train_loss: -805.92859, val_loss: -575.77173, val_recall@20: 0.13046, val_precision@20: 0.04421, val_ndcg@20: 0.09847\n",
            "[Iteration 3600/10000] train_loss: -866.34863, val_loss: -612.15955, val_recall@20: 0.13018, val_precision@20: 0.04421, val_ndcg@20: 0.09862\n",
            "[Iteration 3800/10000] train_loss: -900.99286, val_loss: -641.84155, val_recall@20: 0.1272, val_precision@20: 0.04358, val_ndcg@20: 0.0975\n",
            "[Iteration 4000/10000] train_loss: -945.25812, val_loss: -676.82434, val_recall@20: 0.13064, val_precision@20: 0.04403, val_ndcg@20: 0.09821\n",
            "[Iteration 4200/10000] train_loss: -946.45929, val_loss: -711.03717, val_recall@20: 0.13187, val_precision@20: 0.04412, val_ndcg@20: 0.09968\n",
            "[Iteration 4400/10000] train_loss: -982.6908, val_loss: -739.3869, val_recall@20: 0.13221, val_precision@20: 0.04394, val_ndcg@20: 0.09937\n",
            "[Iteration 4600/10000] train_loss: -1070.3175, val_loss: -767.86102, val_recall@20: 0.13209, val_precision@20: 0.04367, val_ndcg@20: 0.10082\n",
            "[Iteration 4800/10000] train_loss: -1060.46704, val_loss: -795.47803, val_recall@20: 0.13215, val_precision@20: 0.04394, val_ndcg@20: 0.09951\n",
            "[Iteration 5000/10000] train_loss: -1112.70361, val_loss: -819.65924, val_recall@20: 0.13253, val_precision@20: 0.04394, val_ndcg@20: 0.10075\n",
            "[Iteration 5200/10000] train_loss: -1168.2699, val_loss: -837.81134, val_recall@20: 0.13266, val_precision@20: 0.04385, val_ndcg@20: 0.10071\n",
            "[Iteration 5400/10000] train_loss: -1215.89587, val_loss: -872.39417, val_recall@20: 0.1328, val_precision@20: 0.04412, val_ndcg@20: 0.10082\n",
            "[Iteration 5600/10000] train_loss: -1303.04578, val_loss: -897.48364, val_recall@20: 0.13495, val_precision@20: 0.04439, val_ndcg@20: 0.10132\n",
            "[Iteration 5800/10000] train_loss: -1232.8877, val_loss: -922.10242, val_recall@20: 0.1337, val_precision@20: 0.0443, val_ndcg@20: 0.10122\n",
            "[Iteration 6000/10000] train_loss: -1278.02905, val_loss: -932.31073, val_recall@20: 0.13386, val_precision@20: 0.04394, val_ndcg@20: 0.10107\n",
            "[Iteration 6200/10000] train_loss: -1295.96045, val_loss: -959.50214, val_recall@20: 0.1327, val_precision@20: 0.04403, val_ndcg@20: 0.10092\n",
            "[Iteration 6400/10000] train_loss: -1349.15222, val_loss: -983.88721, val_recall@20: 0.13397, val_precision@20: 0.04394, val_ndcg@20: 0.10124\n",
            "[Iteration 6600/10000] train_loss: -1354.42126, val_loss: -1003.92096, val_recall@20: 0.13344, val_precision@20: 0.04394, val_ndcg@20: 0.10102\n",
            "[Iteration 6800/10000] train_loss: -1393.69189, val_loss: -1012.74078, val_recall@20: 0.13283, val_precision@20: 0.04403, val_ndcg@20: 0.10098\n",
            "[Iteration 7000/10000] train_loss: -1419.86414, val_loss: -1035.78625, val_recall@20: 0.13423, val_precision@20: 0.04412, val_ndcg@20: 0.10137\n",
            "[Iteration 7200/10000] train_loss: -1392.54175, val_loss: -1058.11084, val_recall@20: 0.13391, val_precision@20: 0.04403, val_ndcg@20: 0.10121\n",
            "[Iteration 7400/10000] train_loss: -1452.60876, val_loss: -1065.14368, val_recall@20: 0.13455, val_precision@20: 0.04421, val_ndcg@20: 0.10146\n",
            "[Iteration 7600/10000] train_loss: -1531.67334, val_loss: -1077.27222, val_recall@20: 0.13373, val_precision@20: 0.04403, val_ndcg@20: 0.10116\n",
            "[Iteration 7800/10000] train_loss: -1503.79089, val_loss: -1097.34448, val_recall@20: 0.13446, val_precision@20: 0.04403, val_ndcg@20: 0.10124\n",
            "[Iteration 8000/10000] train_loss: -1598.078, val_loss: -1121.18481, val_recall@20: 0.13386, val_precision@20: 0.04394, val_ndcg@20: 0.10121\n",
            "[Iteration 8200/10000] train_loss: -1545.50879, val_loss: -1117.99304, val_recall@20: 0.13386, val_precision@20: 0.04403, val_ndcg@20: 0.10124\n",
            "[Iteration 8400/10000] train_loss: -1564.67139, val_loss: -1128.31262, val_recall@20: 0.13417, val_precision@20: 0.04412, val_ndcg@20: 0.10146\n",
            "[Iteration 8600/10000] train_loss: -1634.27649, val_loss: -1142.95947, val_recall@20: 0.13434, val_precision@20: 0.04421, val_ndcg@20: 0.10147\n",
            "[Iteration 8800/10000] train_loss: -1549.29211, val_loss: -1167.4093, val_recall@20: 0.13432, val_precision@20: 0.0443, val_ndcg@20: 0.10168\n",
            "[Iteration 9000/10000] train_loss: -1577.82471, val_loss: -1162.2998, val_recall@20: 0.13363, val_precision@20: 0.04376, val_ndcg@20: 0.10118\n",
            "[Iteration 9200/10000] train_loss: -1603.74878, val_loss: -1170.44067, val_recall@20: 0.13421, val_precision@20: 0.04412, val_ndcg@20: 0.1016\n",
            "[Iteration 9400/10000] train_loss: -1642.72961, val_loss: -1189.03076, val_recall@20: 0.13402, val_precision@20: 0.04394, val_ndcg@20: 0.1014\n",
            "[Iteration 9600/10000] train_loss: -1687.16772, val_loss: -1185.20386, val_recall@20: 0.13405, val_precision@20: 0.04403, val_ndcg@20: 0.10149\n",
            "[Iteration 9800/10000] train_loss: -1667.3241, val_loss: -1203.19702, val_recall@20: 0.13405, val_precision@20: 0.04403, val_ndcg@20: 0.10157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot"
      ],
      "metadata": {
        "id": "-CxObENG7Wfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
        "plt.plot(iters, train_losses, label='train')\n",
        "plt.plot(iters, val_losses, label='validation')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')\n",
        "plt.title('training and validation loss curves')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "XK5uFYNN7aGd",
        "outputId": "1b159f17-0d42-4062-fe5a-5da042d6780e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f2 = plt.figure()\n",
        "plt.plot(iters, val_recall_at_ks, label='recall_at_k')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('recall_at_k')\n",
        "plt.title('recall_at_k curves')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "zgF49O4z7bNV",
        "outputId": "e5236fd9-e2ef-48a7-87c5-97c23125deab"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate on test set\n",
        "model.eval()\n",
        "test_edge_index = test_edge_index.to(device)\n",
        "\n",
        "test_loss, test_recall, test_precision, test_ndcg = evaluation(model, \n",
        "                                                               test_edge_index, \n",
        "                                                               [train_edge_index, val_edge_index], \n",
        "                                                               K, \n",
        "                                                               LAMBDA\n",
        "                                                              )\n",
        "\n",
        "print(f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TowFPeX7cL-",
        "outputId": "aadcf298-9f48-4784-8329-9c6225bc41f0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test_loss: -1212.86658, test_recall@20: 0.12163, test_precision@20: 0.04429, test_ndcg@20: 0.09799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vi2warOl7dd1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}